{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fdbc8b",
   "metadata": {},
   "source": [
    "## ML_Assignment_13\n",
    "1. Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "2. What role does Bayes' theorem play in the concept learning principle?\n",
    "3. Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about doing it?\n",
    "5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues?\n",
    "6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder?\n",
    "7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D).\n",
    "8. In order to prepare for the test, a student knows that there will be one question in the exam that is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.\n",
    "     1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "     2. Given the student's solution, what is the likelihood that the problem was of form A?\n",
    "9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "     1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "    2. On a daily basis, how many fake photographs (photographs taken when there is no customer) and how many missed photographs (photographs taken when there is a customer) are there?\n",
    "\n",
    "    3. Explain likelihood that there is a customer if there is a photograph?\n",
    "10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief network to represent the conditional independence assumptions of the Nave Bayes classifier for the match winning prediction problem in Section 6.4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef035294",
   "metadata": {},
   "source": [
    "### Ans 1\n",
    "\n",
    "Certainly, let's illustrate the concepts of Prior, Posterior, and Likelihood with a simple example:\n",
    "\n",
    "**Scenario**: Consider a medical test for a rare disease. We want to determine whether a patient has the disease based on the test result.\n",
    "\n",
    "1. **Prior Probability**: The prior probability is the initial belief or probability that a patient has the disease before any test results are considered. Let's say that for the general population, the prior probability of having the disease is 0.01 or 1%.\n",
    "\n",
    "2. **Likelihood Probability**: The likelihood probability represents the probability of observing a particular test result (positive or negative) given whether the patient has the disease. For instance, if the test is 95% accurate, the likelihood of a positive result given the patient has the disease might be 0.95, and the likelihood of a negative result given the patient doesn't have the disease might be 0.95 as well.\n",
    "\n",
    "3. **Posterior Probability**: The posterior probability is the updated probability of having the disease after considering the test result. It combines the prior probability and the likelihood probability using Bayes' theorem. The formula for calculating the posterior probability is:\n",
    "\n",
    "   ```\n",
    "   Posterior Probability = (Likelihood Probability * Prior Probability) / Evidence\n",
    "   ```\n",
    "\n",
    "In this example, the posterior probability quantifies the patient's updated likelihood of having the disease based on both prior beliefs and the test result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ec49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability: 0.01\n",
      "Likelihood Probability: 0.95\n",
      "Evidence (Total Probability of Test Result): 0.059000000000000045\n",
      "Posterior Probability (Updated Probability of Having the Disease): 0.16101694915254225\n"
     ]
    }
   ],
   "source": [
    "# Define prior probability\n",
    "# Prior probability of having the disease is 1%\n",
    "Prior_Probability = 0.01  \n",
    "\n",
    "# Define likelihood probability\n",
    "# Likelihood of a positive test result given the disease\n",
    "Likelihood_Probability = 0.95  \n",
    "\n",
    "# Calculate evidence (total probability of the test result)\n",
    "Evidence = (Likelihood_Probability * Prior_Probability) + ((1 - Prior_Probability) * (1 - Likelihood_Probability))\n",
    "\n",
    "# Calculate posterior probability\n",
    "Posterior_Probability = (Likelihood_Probability * Prior_Probability) / Evidence\n",
    "\n",
    "# Print the results\n",
    "print(\"Prior Probability:\", Prior_Probability)\n",
    "print(\"Likelihood Probability:\", Likelihood_Probability)\n",
    "print(\"Evidence (Total Probability of Test Result):\", Evidence)\n",
    "print(\"Posterior Probability (Updated Probability of Having the Disease):\", Posterior_Probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf706970",
   "metadata": {},
   "source": [
    "### Ans 2\n",
    "\n",
    "Bayes' theorem plays a fundamental role in the concept learning principle, particularly in the context of probabilistic concept learning. Concept learning involves the process of acquiring knowledge about categories or concepts from examples or data. Bayes' theorem provides a mathematical framework for updating and refining the learner's beliefs about these concepts as it encounters new evidence or observations.\n",
    "\n",
    "Here's how Bayes' theorem is applied in concept learning:\n",
    "\n",
    "1. **Prior Beliefs**: The learner starts with initial beliefs or prior probabilities about the concepts it is trying to learn. These prior beliefs represent what the learner knows or assumes about the concepts before observing any data.\n",
    "\n",
    "2. **Observations (Evidence)**: As the learner encounters new examples or observations, it collects evidence about the concepts. This evidence can be in the form of labeled examples (positive or negative) or features associated with the concepts.\n",
    "\n",
    "3. **Likelihood Probability**: Bayes' theorem is used to calculate the likelihood probability, which represents the probability of observing the evidence (data) given the current beliefs about the concepts. The likelihood quantifies how well the observations align with the existing concept hypotheses.\n",
    "\n",
    "4. **Posterior Beliefs**: Bayes' theorem is then applied to update the learner's prior beliefs using the likelihood probability and normalize the result. This yields the posterior probability distribution over the concepts. The posterior beliefs represent the refined knowledge about the concepts based on the observed evidence.\n",
    "\n",
    "5. **Decision and Learning**: The learner can make decisions based on the posterior beliefs, such as classifying new examples or making inferences about the concepts. Additionally, the updated posterior beliefs serve as the new prior beliefs when more evidence is encountered, allowing the learner to adapt and refine its understanding of the concepts over time.\n",
    "\n",
    "In summary, Bayes' theorem plays a pivotal role in concept learning by providing a principled framework for updating beliefs, incorporating evidence, and making informed decisions about the underlying concepts based on observed data. It allows the learner to iteratively refine its understanding of the concepts as it encounters new information, making it a powerful tool in machine learning and artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835adb8b",
   "metadata": {},
   "source": [
    "### Ans 3\n",
    "\n",
    "One common real-life application of the Naïve Bayes classifier is in email spam filtering. Email services like Gmail and Outlook use Naïve Bayes-based spam filters to automatically classify incoming emails as either \"spam\" (unwanted) or \"ham\" (legitimate).\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. **Training Phase**: During the training phase, the email service analyzes a large dataset of labeled emails. These emails are categorized as either spam or ham based on user feedback. The Naïve Bayes classifier learns from these labeled examples and estimates the probabilities of different words or features appearing in spam and ham emails.\n",
    "\n",
    "2. **Feature Extraction**: The classifier extracts features from incoming emails, such as words in the subject line, sender's address, and content. It calculates the likelihood of these features occurring in spam and ham emails based on what it learned during training.\n",
    "\n",
    "3. **Classification**: When a new email arrives, the Naïve Bayes classifier calculates the posterior probability of the email being spam or ham based on the observed features. It combines the prior probability (the probability of an email being spam or ham without considering the features) with the likelihood probabilities (the probabilities of the observed features given spam or ham).\n",
    "\n",
    "4. **Thresholding**: The classifier compares the calculated probabilities and assigns the email to the category with the higher probability. If the probability of spam is above a certain threshold, the email is classified as spam; otherwise, it's classified as ham.\n",
    "\n",
    "5. **User Feedback**: As users interact with their email accounts, they can mark emails as spam or move them to the inbox. These actions provide continuous feedback to further improve the classifier's accuracy.\n",
    "\n",
    "This real-life application of the Naïve Bayes classifier efficiently filters out unwanted emails, reducing inbox clutter and improving the user experience by ensuring that legitimate emails are not mistakenly classified as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24aaedd",
   "metadata": {},
   "source": [
    "### Ans 4\n",
    "\n",
    "Yes, the Naïve Bayes classifier can be used with continuous numeric data, but it requires some modifications because the standard Naïve Bayes algorithm assumes categorical or discrete features. However, you can apply different variants of the Naïve Bayes classifier designed for continuous data. Two common approaches are the Gaussian Naïve Bayes and Kernel Density Estimation (KDE) Naïve Bayes classifiers:\n",
    "\n",
    "1. **Gaussian Naïve Bayes**:\n",
    "   - **Assumption**: This variant assumes that the features are normally distributed within each class.\n",
    "   - **How it works**: For each feature and class, it estimates the mean and standard deviation of the feature values. When making predictions, it calculates the likelihood using the Gaussian (normal) probability density function.\n",
    "   - **Implementation**: You can use the `GaussianNB` class from scikit-learn in Python.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "2. **KDE Naïve Bayes**:\n",
    "   - **Assumption**: This variant makes no assumptions about the distribution of features and is more flexible.\n",
    "   - **How it works**: It uses Kernel Density Estimation to estimate the probability density function of the data within each class. This provides a non-parametric approach to modeling continuous data.\n",
    "   - **Implementation**: You can use libraries like scikit-learn to implement the KDE Naïve Bayes classifier.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import KernelDensityNB\n",
    "clf = KernelDensityNB()\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "When using the Naïve Bayes classifier with continuous data, it's essential to preprocess the data appropriately and ensure that the underlying assumptions (normality for Gaussian Naïve Bayes or the absence of assumptions for KDE Naïve Bayes) are met or reasonable for your specific dataset. Additionally, feature scaling and handling missing values can be important steps in preparing continuous data for Naïve Bayes classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319fa19",
   "metadata": {},
   "source": [
    "### Ans 5\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Probabilistic Graphical Models, are probabilistic models used for representing and reasoning about uncertainty and complex relationships among variables. They work by constructing a directed acyclic graph (DAG) where nodes represent random variables, and edges depict probabilistic dependencies between variables. BBNs employ Bayes' theorem to update beliefs as evidence is observed, allowing for probabilistic inference.\n",
    "\n",
    "BBNs find applications in diverse fields, including healthcare (diagnosis and prognosis), finance (risk assessment), natural language processing (language understanding), and more. They excel in scenarios involving uncertainty, incomplete data, and causal relationships. While powerful, BBNs have limitations, such as scalability and their assumption of conditional independence between non-connected variables, making them more suitable for certain problem domains than others. They are a valuable tool but not a universal solution for all issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc2327",
   "metadata": {},
   "source": [
    "### Ans 6\n",
    "\n",
    "To find the chances that an alarm would be triggered when an individual is actually an intruder (i.e., the probability of a true positive), you can use Bayes' theorem. The formula for this is:\n",
    "\n",
    "\\[P(I = 1|A = 1) = \\frac{P(A = 1|I = 1) \\cdot P(I = 1)}{P(A = 1)}\\]\n",
    "\n",
    "You are given:\n",
    "\n",
    "- \\(P(A = 1|I = 1) = 0.98\\) (the probability of an alarm when there is an intruder).\n",
    "- \\(P(A = 1|I = 0) = 0.001\\) (the probability of an alarm when there is no intruder).\n",
    "- \\(P(I = 1) = 0.00001\\) (the likelihood of an intruder in the passenger population).\n",
    "\n",
    "To calculate \\(P(A = 1)\\), you can use the law of total probability:\n",
    "\n",
    "\\[P(A = 1) = P(A = 1|I = 1) \\cdot P(I = 1) + P(A = 1|I = 0) \\cdot P(I = 0)\\]\n",
    "\n",
    "Since \\(P(I = 0) = 1 - P(I = 1)\\), you can calculate \\(P(A = 1)\\) and then use it in Bayes' theorem to find \\(P(I = 1|A = 1)\\):\n",
    "\n",
    "\\[P(I = 1|A = 1) = \\frac{P(A = 1|I = 1) \\cdot P(I = 1)}{P(A = 1|I = 1) \\cdot P(I = 1) + P(A = 1|I = 0) \\cdot P(I = 0)}\\]\n",
    "\n",
    "Now, plug in the values and calculate:\n",
    "\n",
    "\\[P(I = 1|A = 1) = \\frac{0.98 \\cdot 0.00001}{0.98 \\cdot 0.00001 + 0.001 \\cdot (1 - 0.00001)}\\]\n",
    "\n",
    "Calculate the numerator and denominator:\n",
    "\n",
    "\\[P(I = 1|A = 1) = \\frac{0.0000098}{0.0000098 + 0.000999}\\]\n",
    "\n",
    "Now, calculate the final probability:\n",
    "\n",
    "\\[P(I = 1|A = 1) \\approx 0.009755\\]\n",
    "\n",
    "So, the chances that an alarm would be triggered when an individual is actually an intruder are approximately 0.009755 or 0.9755%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f42dc",
   "metadata": {},
   "source": [
    "### Ans 7\n",
    "\n",
    "To calculate the likelihood that a person who tests positive is actually immune (resistant to the antibiotic), we can use Bayes' theorem. Let's define the relevant probabilities:\n",
    "\n",
    "- \\(T = 1\\) indicates a positive test result.\n",
    "- \\(D = 1\\) indicates immunity (antibiotic-resistant).\n",
    "- \\(D = 0\\) indicates non-immunity (not antibiotic-resistant).\n",
    "\n",
    "We are given the following probabilities:\n",
    "\n",
    "- \\(P(T = 1|D = 0) = 0.01\\) (false positives, i.e., probability of a positive test result given non-immunity).\n",
    "- \\(P(T = 0|D = 1) = 0.05\\) (false negatives, i.e., probability of a negative test result given immunity).\n",
    "- \\(P(D = 1) = 0.02\\) (probability of being antibiotic-resistant).\n",
    "\n",
    "We want to calculate \\(P(D = 1|T = 1)\\) (the likelihood of immunity given a positive test result).\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "\\[P(D = 1|T = 1) = \\frac{P(T = 1|D = 1) \\cdot P(D = 1)}{P(T = 1|D = 1) \\cdot P(D = 1) + P(T = 1|D = 0) \\cdot P(D = 0)}\\]\n",
    "\n",
    "Now, plug in the values:\n",
    "\n",
    "\\[P(D = 1|T = 1) = \\frac{0.95 \\cdot 0.02}{0.95 \\cdot 0.02 + 0.01 \\cdot (1 - 0.02)}\\]\n",
    "\n",
    "Calculate the numerator and denominator:\n",
    "\n",
    "\\[P(D = 1|T = 1) = \\frac{0.019}{0.019 + 0.0098}\\]\n",
    "\n",
    "Now, calculate the final probability:\n",
    "\n",
    "\\[P(D = 1|T = 1) \\approx 0.6605\\]\n",
    "\n",
    "So, the likelihood that a person who tests positive is actually immune (antibiotic-resistant) is approximately 0.6605 or 66.05%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b57ed",
   "metadata": {},
   "source": [
    "### Ans 8\n",
    "\n",
    "To calculate the likelihood that the student can solve the exam problem, we can use the law of total probability. Let \\(S\\) be the event that the student can solve the exam problem, and let \\(A\\), \\(B\\), and \\(C\\) be the events that the exam problem is of form A, B, or C, respectively.\n",
    "\n",
    "We are given the probabilities:\n",
    "\n",
    "- \\(P(A) = 0.30\\) (the probability that the exam problem is of form A).\n",
    "- \\(P(B) = 0.20\\) (the probability that the exam problem is of form B).\n",
    "- \\(P(C) = 0.50\\) (the probability that the exam problem is of form C).\n",
    "\n",
    "We are also given the conditional probabilities:\n",
    "\n",
    "- \\(P(S|A) = \\frac{9}{10}\\) (the probability that the student can solve the problem given it's of form A).\n",
    "- \\(P(S|B) = \\frac{2}{10}\\) (the probability that the student can solve the problem given it's of form B).\n",
    "- \\(P(S|C) = \\frac{6}{10}\\) (the probability that the student can solve the problem given it's of form C).\n",
    "\n",
    "To calculate the likelihood that the student can solve the exam problem (\\(P(S)\\)), we can use the law of total probability:\n",
    "\n",
    "\\[P(S) = P(S|A) \\cdot P(A) + P(S|B) \\cdot P(B) + P(S|C) \\cdot P(C)\\]\n",
    "\n",
    "Now, plug in the values:\n",
    "\n",
    "\\[P(S) = \\left(\\frac{9}{10}\\right) \\cdot (0.30) + \\left(\\frac{2}{10}\\right) \\cdot (0.20) + \\left(\\frac{6}{10}\\right) \\cdot (0.50)\\]\n",
    "\n",
    "Calculate the sum:\n",
    "\n",
    "\\[P(S) = 0.27 + 0.04 + 0.30\\]\n",
    "\n",
    "\\[P(S) = 0.61\\]\n",
    "\n",
    "So, the likelihood that the student can solve the exam problem is 0.61 or 61%.\n",
    "\n",
    "Now, to find the likelihood that the problem was of form A given the student's solution (\\(P(A|S)\\)), we can use Bayes' theorem:\n",
    "\n",
    "\\[P(A|S) = \\frac{P(S|A) \\cdot P(A)}{P(S)}\\]\n",
    "\n",
    "Plug in the values:\n",
    "\n",
    "\\[P(A|S) = \\frac{\\left(\\frac{9}{10}\\right) \\cdot (0.30)}{0.61}\\]\n",
    "\n",
    "Calculate the probability:\n",
    "\n",
    "\\[P(A|S) \\approx 0.4426\\]\n",
    "\n",
    "So, the likelihood that the problem was of form A given the student's solution is approximately 0.4426 or 44.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f00236",
   "metadata": {},
   "source": [
    "### Ans 9\n",
    "\n",
    "Let's break down each part of the question:\n",
    "\n",
    "**A. How many customers come into the bank on a daily basis (10 hours)?**\n",
    "\n",
    "To calculate the number of customers who come into the bank on a daily basis, we first need to determine how many 5-minute intervals there are in 10 hours. There are \\(10 \\times 60 / 5 = 120\\) intervals in 10 hours. \n",
    "\n",
    "In each interval, there is a 5% chance of a customer coming in. So, the expected number of customers is \\(0.05 \\times 120 = 6\\).\n",
    "\n",
    "So, on average, 6 customers come into the bank on a daily basis.\n",
    "\n",
    "**B. On a daily basis, how many fake photographs and how many missed photographs are there?**\n",
    "\n",
    "1. **Fake Photographs (Photographs taken when there is no customer):**\n",
    "   - In each interval, there is a 95% chance (complement of 5%) of no customer coming in.\n",
    "   - If there is no customer, there is a 10% chance of a false photograph being taken.\n",
    "   - So, the expected number of fake photographs in each interval is \\(0.95 \\times 0.10 = 0.095\\).\n",
    "   - Over 120 intervals (10 hours), the expected number of fake photographs is \\(0.095 \\times 120 = 11.4\\).\n",
    "\n",
    "2. **Missed Photographs (Photographs taken when there is a customer):**\n",
    "   - In each interval, there is a 5% chance of a customer coming in.\n",
    "   - If there is a customer, there is a 1% chance of the photograph being missed.\n",
    "   - So, the expected number of missed photographs in each interval is \\(0.05 \\times 0.01 = 0.0005\\).\n",
    "   - Over 120 intervals (10 hours), the expected number of missed photographs is \\(0.0005 \\times 120 = 0.06\\).\n",
    "\n",
    "So, on average, there are approximately 11.4 fake photographs and 0.06 missed photographs on a daily basis.\n",
    "\n",
    "**C. Explain the likelihood that there is a customer if there is a photograph?**\n",
    "\n",
    "To calculate the likelihood that there is a customer if there is a photograph, we can use Bayes' theorem. Let \\(C\\) be the event that there is a customer, and \\(P\\) be the event that there is a photograph taken.\n",
    "\n",
    "We want to find \\(P(C|P)\\), the probability that there is a customer given that there is a photograph. Using Bayes' theorem:\n",
    "\n",
    "\\[P(C|P) = \\frac{P(P|C) \\cdot P(C)}{P(P)}\\]\n",
    "\n",
    "We know the following probabilities:\n",
    "\n",
    "- \\(P(C) = 0.05\\) (the probability that there is a customer in each 5-minute interval).\n",
    "- \\(P(P|C) = 0.99\\) (the probability of a photograph when there is a customer).\n",
    "- \\(P(P|\\neg C) = 0.10\\) (the probability of a photograph when there is no customer).\n",
    "- \\(P(\\neg C) = 0.95\\) (the probability that there is no customer in each 5-minute interval).\n",
    "\n",
    "Now, we need to calculate \\(P(P)\\), the probability that there is a photograph, which can be done using the law of total probability:\n",
    "\n",
    "\\[P(P) = P(P|C) \\cdot P(C) + P(P|\\neg C) \\cdot P(\\neg C)\\]\n",
    "\n",
    "Now, plug in the values and calculate:\n",
    "\n",
    "\\[P(P) = (0.99 \\cdot 0.05) + (0.10 \\cdot 0.95)\\]\n",
    "\n",
    "\\[P(P) = 0.0495 + 0.095 = 0.1445\\]\n",
    "\n",
    "Now, we can calculate \\(P(C|P)\\) using Bayes' theorem:\n",
    "\n",
    "\\[P(C|P) = \\frac{0.99 \\cdot 0.05}{0.1445}\\]\n",
    "\n",
    "Calculate the probability:\n",
    "\n",
    "\\[P(C|P) \\approx 0.3419\\]\n",
    "\n",
    "So, the likelihood that there is a customer if there is a photograph is approximately 0.3419 or 34.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bcb53",
   "metadata": {},
   "source": [
    "### Ans 10\n",
    "\n",
    "Creating a conditional probability table (CPT) for the node \"Won Toss\" in a Bayesian Belief Network (BBN) for a Naïve Bayes classifier involves specifying the conditional probabilities of \"Won Toss\" given the class variable (e.g., \"Match Outcome\"). In this case, we'll assume a binary class variable where \"Match Outcome\" can be either \"Win\" or \"Lose.\" The CPT represents the probability of winning the toss for each class.\n",
    "\n",
    "Let's create a simplified CPT for \"Won Toss\" based on the conditional independence assumptions of a Naïve Bayes classifier for a match-winning prediction problem:\n",
    "\n",
    "| Match Outcome | Won Toss = Yes | Won Toss = No |\n",
    "|---------------|----------------|---------------|\n",
    "| Win           | \\(P(WonToss=Yes|Win)\\) | \\(P(WonToss=No|Win)\\) |\n",
    "| Lose          | \\(P(WonToss=Yes|Lose)\\) | \\(P(WonToss=No|Lose)\\) |\n",
    "\n",
    "In a Naïve Bayes classifier, the assumption is that the features (or variables) are conditionally independent given the class variable. In this context, it means that whether a team wins the toss or not is independent of other factors (features) given the match outcome.\n",
    "\n",
    "You would populate the CPT with actual probabilities based on your dataset or domain knowledge. For example, if you have historical data and find that the probability of winning the toss when winning the match is 0.7 and the probability of not winning the toss when winning the match is 0.3, you would fill in those values accordingly in the table. Similarly, you would calculate the probabilities for the \"Lose\" class.\n",
    "\n",
    "The CPT allows the BBN to make predictions about \"Won Toss\" based on observed data for \"Match Outcome\" while respecting the conditional independence assumptions of the Naïve Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1246c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
