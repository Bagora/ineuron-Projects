{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c876ad8a",
   "metadata": {},
   "source": [
    "## NLP_Assignment_6\n",
    "1. What are Vanilla autoencoders\n",
    "2. What are Sparse autoencoders\n",
    "3. What are Denoising autoencoders\n",
    "4. What are Convolutional autoencoders\n",
    "5. What are Stacked autoencoders\n",
    "6. Explain how to generate sentences using LSTM autoencoders\n",
    "7. Explain Extractive summarization\n",
    "8. Explain Abstractive summarization\n",
    "9. Explain Beam search\n",
    "10. Explain Length normalization\n",
    "11. Explain Coverage normalization\n",
    "12. Explain ROUGE metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e63be24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 0.0834\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0832\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0831\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0831\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0831\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0830\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0830\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "'''Ans 1:- Vanilla autoencoders are a type of neural network used for\n",
    "unsupervised learning and dimensionality reduction. They consist of an\n",
    "encoder that compresses input data into a lower-dimensional\n",
    "representation and a decoder that attempts to reconstruct the original\n",
    "input from this representation. \n",
    "\n",
    "In this example, the encoder compresses the input data,\n",
    "and the decoder tries to reconstruct it, with the aim of\n",
    "learning a meaningful representation in the bottleneck layer\n",
    "(encoded). This is a basic illustration of a vanilla autoencoder,\n",
    "which can be extended for various applications like data\n",
    "denoising and feature extraction.\n",
    "\n",
    "'encoded_data' contains the encoded representations,\n",
    "and 'decoded_data' contains the reconstructed data.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# the dimensionscfor 28x28 pixel images\n",
    "input_dim = 784\n",
    "encoding_dim = 128\n",
    "\n",
    "# encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# decoder\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "num_samples = 1000\n",
    "X_train = np.random.rand(num_samples, input_dim)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32)\n",
    "\n",
    "encoder_model = Model(input_layer, encoded)\n",
    "encoded_data = encoder_model.predict(X_train)\n",
    "\n",
    "decoded_data = autoencoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e28dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 9ms/step - loss: 0.2155 - val_loss: 0.1375\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1207 - val_loss: 0.1059\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0995 - val_loss: 0.0922\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0891 - val_loss: 0.0847\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0832 - val_loss: 0.0803\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0796 - val_loss: 0.0776\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0772 - val_loss: 0.0758\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0756 - val_loss: 0.0745\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0744 - val_loss: 0.0735\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0735 - val_loss: 0.0727\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0728 - val_loss: 0.0721\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0722 - val_loss: 0.0716\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0717 - val_loss: 0.0711\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0713 - val_loss: 0.0708\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0709 - val_loss: 0.0705\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0706 - val_loss: 0.0702\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0704 - val_loss: 0.0700\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0701 - val_loss: 0.0698\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0699 - val_loss: 0.0696\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0698 - val_loss: 0.0694\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0696 - val_loss: 0.0693\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0695 - val_loss: 0.0692\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0693 - val_loss: 0.0691\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0692 - val_loss: 0.0689\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0691 - val_loss: 0.0689\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0690 - val_loss: 0.0688\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0689 - val_loss: 0.0687\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0688 - val_loss: 0.0686\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0687 - val_loss: 0.0685\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0687 - val_loss: 0.0685\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0686 - val_loss: 0.0684\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0685 - val_loss: 0.0684\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0685 - val_loss: 0.0683\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0684 - val_loss: 0.0683\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0684 - val_loss: 0.0683\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0683 - val_loss: 0.0682\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0683 - val_loss: 0.0681\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0682 - val_loss: 0.0681\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0682 - val_loss: 0.0680\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0681 - val_loss: 0.0680\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0681 - val_loss: 0.0680\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0681 - val_loss: 0.0679\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0680 - val_loss: 0.0679\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0680 - val_loss: 0.0678\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0679 - val_loss: 0.0678\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0679 - val_loss: 0.0678\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0679 - val_loss: 0.0678\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0678 - val_loss: 0.0677\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0678 - val_loss: 0.0677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230eaad68f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ans 2:- Sparse autoencoders are a variant of autoencoders that\n",
    "encourage a sparse representation in the encoder's hidden layer.\n",
    "They use techniques like L1 regularization to limit the number\n",
    "of active neurons.This code defines a sparse autoencoder\n",
    "using the Keras library, trains it on the MNIST dataset, and can\n",
    "be used to extract a sparse representation ('encoded') of the\n",
    "input data.'''\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load a dataset (e.g., MNIST)\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Define a sparse autoencoder\n",
    "input_layer = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu', activity_regularizer=tf.keras.regularizers.l1(1e-5))(input_layer)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726839ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.2301 - val_loss: 0.1558\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1416 - val_loss: 0.1295\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1244 - val_loss: 0.1194\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1170 - val_loss: 0.1151\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1132 - val_loss: 0.1123\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1109 - val_loss: 0.1108\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1095 - val_loss: 0.1099\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1084 - val_loss: 0.1090\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1076 - val_loss: 0.1084\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1070 - val_loss: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230e97432e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ans 3:- Denoising autoencoders are a type of autoencoder designed\n",
    "to learn robust feature representations by training on noisy\n",
    "data. They take noisy inputs and aim to reconstruct the\n",
    "original, clean data. This code demonstrates how to create and train\n",
    "a denoising autoencoder on noisy MNIST data, and 'encoded'\n",
    "contains the denoised representations of the input images.\n",
    "After training, we can use 'encoded' as a denoised representation.'''\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Create noisy data\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Define a denoising autoencoder\n",
    "input_layer = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84abd7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1067 - val_loss: 0.0660\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0654 - val_loss: 0.0643\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0642 - val_loss: 0.0635\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0634 - val_loss: 0.0628\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0629 - val_loss: 0.0624\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.0626 - val_loss: 0.0621\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0623 - val_loss: 0.0618\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0621 - val_loss: 0.0616\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0619 - val_loss: 0.0614\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0617 - val_loss: 0.0613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230eaabc6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ans 4:- Convolutional autoencoders are a type of autoencoder that\n",
    "uses convolutional neural networks (CNNs) for feature\n",
    "extraction and reconstruction of images. They are particularly suited\n",
    "for tasks like image denoising and compression. In these\n",
    "autoencoders, convolutional layers in the encoder capture hierarchical\n",
    "image features, while transposed convolutional layers in the\n",
    "decoder reconstruct the original image. here is an example using\n",
    "Keras to create a convolutional autoencoder for image\n",
    "reconstruction:'''\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess MNIST data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Define a convolutional autoencoder\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(encoded)\n",
    "decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=128, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 5:- Stacked autoencoders are a type of neural network\n",
    "architecture composed of multiple layers of autoencoders. Each layer\n",
    "learns to capture progressively higher-level features from the\n",
    "input data. Stacking multiple autoencoders allows for more\n",
    "complex feature extraction and dimensionality reduction. Stacked\n",
    "autoencoders are often used for unsupervised pretraining of deep neural\n",
    "networks, as they help initialize weights and improve the network's\n",
    "ability to learn intricate patterns in the data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba620c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 6:- To generate sentences using LSTM autoencoders, follow\n",
    "these steps:- \n",
    "\n",
    "Data Preparation: Prepare a dataset of sentences,\n",
    "tokenize them, and convert them into numerical sequences. \n",
    "\n",
    "Architecture: Design an LSTM autoencoder. The encoder LSTM compresses\n",
    "input sequences into a fixed-size representation, while the\n",
    "decoder LSTM generates sentences from this representation. \n",
    "\n",
    "Training: Train the autoencoder using the input sentences as both\n",
    "input and target. Minimize the reconstruction error. \n",
    "\n",
    "Generation: To generate sentences, input a seed sequence to the\n",
    "encoder and decode it using the decoder LSTM. Sample words at each\n",
    "time step based on predicted probabilities.  \n",
    "\n",
    "Repeat: Iterate the generation process, appending each generated\n",
    "word to the seed sequence, until the desired sentence length or an end\n",
    "token is reached.  By using LSTM autoencoders, the model learns\n",
    "to capture the sequential dependencies in the data, allowing\n",
    "it to generate coherent sentences based on the input seed\n",
    "sequence.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 7:- Extractive summarization is a text summarization\n",
    "technique where the summary is created by selecting and extracting\n",
    "sentences or phrases directly from the original document. It does\n",
    "not generate new sentences but rather identifies the most\n",
    "relevant and informative content based on criteria like sentence\n",
    "importance, coherence, and relevance scores. Extractive summarization\n",
    "methods often employ natural language processing and machine\n",
    "learning algorithms to rank and select sentences that best\n",
    "represent the key information in the source text, resulting in a\n",
    "concise summary that preserves the original content's structure\n",
    "and context.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b64091",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 8:- Abstractive summarization is a text summarization\n",
    "technique that generates concise and coherent summaries by\n",
    "interpreting and rephrasing the source content in a more human-like\n",
    "manner. It goes beyond extraction and can create novel sentences\n",
    "to convey the core ideas. For example, given the input \"The\n",
    "cat sat on the mat,\" an abstractive summarization model might\n",
    "generate \"A cat rested on the soft mat.\" It involves natural\n",
    "language generation techniques and often relies on deep learning\n",
    "models like transformers to achieve this.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb82223",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 9:- Beam search is a search algorithm used in various natural\n",
    "language processing tasks, including machine translation and text\n",
    "generation. It explores multiple possible sequences of words during\n",
    "decoding. Instead of selecting just the most likely word at each\n",
    "step, it maintains a \"beam\" of the top-K candidates. This allows\n",
    "for a broader exploration of possibilities and improves the\n",
    "quality of generated text by considering multiple potential\n",
    "continuations and selecting the best ones based on predefined criteria.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 10:- Length normalization is a technique used in natural\n",
    "language processing to address bias in sequence generation models\n",
    "like beam search. It involves adjusting the model's scoring or\n",
    "ranking of generated sequences based on their length. Longer\n",
    "sequences tend to have lower probabilities, so length normalization\n",
    "ensures fairness by dividing the model's score by the length of\n",
    "the sequence, penalizing overly short or long outputs. This\n",
    "helps produce summaries or translations that are more balanced\n",
    "and contextually appropriate.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468586c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 11:- Coverage normalization is a mechanism used in\n",
    "sequence-to-sequence models for tasks like machine translation and text\n",
    "summarization. It keeps track of how often each source input has been\n",
    "attended to during the decoding process. This helps mitigate issues\n",
    "like repeated words in the generated output. By encouraging the\n",
    "model to attend to uncovered source parts, it promotes more\n",
    "accurate and coherent generation of target sequences by reducing\n",
    "redundancy and improving coverage of the input.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ec62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans 12:- ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "is a metric used for automatic evaluation of the quality of\n",
    "machine-generated text, particularly in tasks like text summarization or\n",
    "machine translation. It measures the similarity between the\n",
    "generated text and reference text using various measures, including\n",
    "precision, recall, and F1-score, for n-grams (word sequences). ROUGE\n",
    "helps assess the effectiveness of algorithms in producing\n",
    "summaries or translations that match human-written references.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
